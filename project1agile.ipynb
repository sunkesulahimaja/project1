{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yLSiBK8gYUKyeW7ED6EqCwUDC5m58lHL","authorship_tag":"ABX9TyMk3CZuk2ROawIsREHMdKsr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Machine Learning Algos"],"metadata":{"id":"Jb4WuM7JwBjX"}},{"cell_type":"code","source":["# Decision Tree\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1) #Delete the target column. This is the Feature\n","y = data['target'] #This is the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create and fit a decision tree classifier\n","classifier = DecisionTreeClassifier()\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {acc*100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0R8YJQowLBD","executionInfo":{"status":"ok","timestamp":1696524820010,"user_tz":-330,"elapsed":4,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"d5705ed2-7400-48e0-f379-7d310eec0197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n"," 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1\n"," 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0\n"," 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n"," 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n"," 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0]\n","Accuracy: 98.54%\n"]}]},{"cell_type":"code","source":["# Random Forest\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1)#Delete the target column to form Features\n","y = data['target'] # This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create and fit a Random Forest classifier\n","classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {acc*100:.2f}%\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"and40TyZwo3r","executionInfo":{"status":"ok","timestamp":1696524874938,"user_tz":-330,"elapsed":677,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"b7ee62f9-2b49-44be-9256-170c11de08ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1\n"," 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1]\n","Accuracy: 100.00%\n"]}]},{"cell_type":"code","source":["# SVM\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1)#Delete the target column to form Features\n","y = data['target']# This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create and fit a Support vector Machine classifier\n","classifier = SVC(kernel='linear', random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {acc*100:.2f}%\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPd8y6S-w2OO","executionInfo":{"status":"ok","timestamp":1696524909833,"user_tz":-330,"elapsed":2933,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"34e87594-9277-4672-bc1b-9f1705ac7c42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1\n"," 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 83.90%\n"]}]},{"cell_type":"code","source":["# Logistic regression\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1)#Delete the target column to form Features\n","y = data['target']# This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create and fit a Logistic Regression classifier\n","classifier = LogisticRegression(random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {acc*100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ns9e7H7kw8pU","executionInfo":{"status":"ok","timestamp":1696524945680,"user_tz":-330,"elapsed":481,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"abc1fb1f-ce30-4ef2-a52e-54a93ab5d0ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 86.34%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"code","source":["# KNN\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1)#Delete the target column to form Features\n","y = data['target']# This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create and fit a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=5)\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {acc*100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnN6YApvxGV0","executionInfo":{"status":"ok","timestamp":1696524985204,"user_tz":-330,"elapsed":439,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"2393bb94-e1ab-4312-bc2d-0f361692d09c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1\n"," 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0\n"," 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0\n"," 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1\n"," 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n"," 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n","Accuracy: 74.63%\n"]}]},{"cell_type":"code","source":["# Naive Bayes\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1) #Delete the target column to form Features\n","y = data['target'] # This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create and fit a Naive Bayes classifier\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3yTIR-KxQMw","executionInfo":{"status":"ok","timestamp":1696525041220,"user_tz":-330,"elapsed":7,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"1f1a31cc-ef5c-430f-e974-5902d11d11e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n"," 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n"," 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8536585365853658\n"]}]},{"cell_type":"code","source":["# Naive Bayes\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","# Split the data into features and target\n","X = data.drop('target', axis=1) #Delete the target column to form Features\n","y = data['target'] # This forms the Label\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n","\n","# Create and fit a Naive Bayes classifier\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","# Evaluate and print the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5V6zGe9C1LW2","executionInfo":{"status":"ok","timestamp":1696609917273,"user_tz":-330,"elapsed":546,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"57074faf-3fd9-4935-9b20-e26c18a231dd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0\n"," 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1\n"," 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0\n"," 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1\n"," 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0\n"," 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n","Accuracy: 0.7951219512195122\n"]}]},{"cell_type":"markdown","source":["**Deep Learning**"],"metadata":{"id":"OLGkthMJx1kT"}},{"cell_type":"code","source":["# DNN\n","\n","# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","#Load the CSV file\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv\")\n","\n","# Split the data into features and target\n","x=df.drop('target',axis=1)#Delete the target column to form Features\n","y=df['target']# This forms the Label\n","\n","# Split the data into training and testing sets\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","\n","#Defining the Model\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=13)) #Input Layer\n","\n","#Creating the Hidden Layers\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","# model.add(Dense(25, activation='relu'))\n","model.add(Dense(1, activation='sigmoid')) #Output Layer\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=150)\n","# model.fit(x_train,y_train, epochs=200)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","#Print the accuracy\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4ZvS6vxx6-w","executionInfo":{"status":"ok","timestamp":1696525400519,"user_tz":-330,"elapsed":22745,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"6f15e1e0-948a-487d-c36e-0049bcbe9b57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","24/24 [==============================] - 1s 3ms/step - loss: 2.0183 - accuracy: 0.5690\n","Epoch 2/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.6484\n","Epoch 3/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6797\n","Epoch 4/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6836\n","Epoch 5/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7161\n","Epoch 6/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6927\n","Epoch 7/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7148\n","Epoch 8/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7305\n","Epoch 9/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7253\n","Epoch 10/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7812\n","Epoch 11/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7474\n","Epoch 12/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7982\n","Epoch 13/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7760\n","Epoch 14/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7552\n","Epoch 15/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7839\n","Epoch 16/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7878\n","Epoch 17/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8086\n","Epoch 18/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8398\n","Epoch 19/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8464\n","Epoch 20/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8229\n","Epoch 21/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8060\n","Epoch 22/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8164\n","Epoch 23/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8346\n","Epoch 24/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8490\n","Epoch 25/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8477\n","Epoch 26/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.7357\n","Epoch 27/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8281\n","Epoch 28/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8190\n","Epoch 29/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8424\n","Epoch 30/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8398\n","Epoch 31/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8451\n","Epoch 32/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8229\n","Epoch 33/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8724\n","Epoch 34/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8190\n","Epoch 35/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8229\n","Epoch 36/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8073\n","Epoch 37/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8294\n","Epoch 38/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177\n","Epoch 39/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8385\n","Epoch 40/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8346\n","Epoch 41/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8151\n","Epoch 42/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8346\n","Epoch 43/150\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8581\n","Epoch 44/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8411\n","Epoch 45/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3366 - accuracy: 0.8646\n","Epoch 46/150\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8542\n","Epoch 47/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8411\n","Epoch 48/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8451\n","Epoch 49/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8555\n","Epoch 50/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8555\n","Epoch 51/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8464\n","Epoch 52/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8333\n","Epoch 53/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8385\n","Epoch 54/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8099\n","Epoch 55/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8294\n","Epoch 56/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8529\n","Epoch 57/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8646\n","Epoch 58/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8737\n","Epoch 59/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8594\n","Epoch 60/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8294\n","Epoch 61/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8568\n","Epoch 62/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8568\n","Epoch 63/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8659\n","Epoch 64/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8633\n","Epoch 65/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8698\n","Epoch 66/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8568\n","Epoch 67/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8516\n","Epoch 68/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8398\n","Epoch 69/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8594\n","Epoch 70/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8672\n","Epoch 71/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8594\n","Epoch 72/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8542\n","Epoch 73/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8464\n","Epoch 74/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8555\n","Epoch 75/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8620\n","Epoch 76/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8633\n","Epoch 77/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8529\n","Epoch 78/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8529\n","Epoch 79/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8346\n","Epoch 80/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8620\n","Epoch 81/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8763\n","Epoch 82/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8516\n","Epoch 83/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8411\n","Epoch 84/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8568\n","Epoch 85/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8776\n","Epoch 86/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8685\n","Epoch 87/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8750\n","Epoch 88/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8555\n","Epoch 89/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8776\n","Epoch 90/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8529\n","Epoch 91/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8646\n","Epoch 92/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8646\n","Epoch 93/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8763\n","Epoch 94/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8672\n","Epoch 95/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8724\n","Epoch 96/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8607\n","Epoch 97/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8372\n","Epoch 98/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8698\n","Epoch 99/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8607\n","Epoch 100/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8607\n","Epoch 101/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8464\n","Epoch 102/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8633\n","Epoch 103/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8594\n","Epoch 104/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8737\n","Epoch 105/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8802\n","Epoch 106/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8607\n","Epoch 107/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8841\n","Epoch 108/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8867\n","Epoch 109/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8607\n","Epoch 110/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8581\n","Epoch 111/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8776\n","Epoch 112/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8763\n","Epoch 113/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8698\n","Epoch 114/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.8763\n","Epoch 115/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8776\n","Epoch 116/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8698\n","Epoch 117/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8763\n","Epoch 118/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8919\n","Epoch 119/150\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8867\n","Epoch 120/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8776\n","Epoch 121/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8633\n","Epoch 122/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8346\n","Epoch 123/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8529\n","Epoch 124/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8633\n","Epoch 125/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8802\n","Epoch 126/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8633\n","Epoch 127/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8503\n","Epoch 128/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8789\n","Epoch 129/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8398\n","Epoch 130/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8971\n","Epoch 131/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8854\n","Epoch 132/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8802\n","Epoch 133/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8893\n","Epoch 134/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8906\n","Epoch 135/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8906\n","Epoch 136/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8815\n","Epoch 137/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.8932\n","Epoch 138/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8750\n","Epoch 139/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8854\n","Epoch 140/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8776\n","Epoch 141/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8906\n","Epoch 142/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.8906\n","Epoch 143/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8906\n","Epoch 144/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8633\n","Epoch 145/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8633\n","Epoch 146/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.8997\n","Epoch 147/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8919\n","Epoch 148/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8893\n","Epoch 149/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8867\n","Epoch 150/150\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8984\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.7899\n","Accuracy: 0.7898832559585571\n"]}]},{"cell_type":"code","source":["# DNN\n","\n","# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","#Load the CSV file\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv\")\n","\n","# Split the data into features and target\n","x=df.drop('target',axis=1)#Delete the target column to form Features\n","y=df['target']# This forms the Label\n","\n","# Split the data into training and testing sets\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","\n","#Defining the Model\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=13)) #Input Layer\n","\n","#Creating the Hidden Layers\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(25, activation='relu'))\n","model.add(Dense(1, activation='sigmoid')) #Output Layer\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","# model.fit(x_train,y_train, epochs=150)\n","model.fit(x_train,y_train, epochs=200)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","#Print the accuracy\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeWgiKV40oK5","executionInfo":{"status":"ok","timestamp":1696609893600,"user_tz":-330,"elapsed":40582,"user":{"displayName":"Himaja S","userId":"18283402293867543434"}},"outputId":"ff3691c9-52a5-4df2-9d71-51544a575249"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 5s 7ms/step - loss: 0.8318 - accuracy: 0.6276\n","Epoch 2/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.6176 - accuracy: 0.6784\n","Epoch 3/200\n","24/24 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6784\n","Epoch 4/200\n","24/24 [==============================] - 0s 8ms/step - loss: 0.6035 - accuracy: 0.6654\n","Epoch 5/200\n","24/24 [==============================] - 0s 9ms/step - loss: 0.5349 - accuracy: 0.7201\n","Epoch 6/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6664 - accuracy: 0.6510\n","Epoch 7/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.6849\n","Epoch 8/200\n","24/24 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7539\n","Epoch 9/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7721\n","Epoch 10/200\n","24/24 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7695\n","Epoch 11/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7214\n","Epoch 12/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7865\n","Epoch 13/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7786\n","Epoch 14/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8151\n","Epoch 15/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8229\n","Epoch 16/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7669\n","Epoch 17/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8047\n","Epoch 18/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8164\n","Epoch 19/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8177\n","Epoch 20/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8320\n","Epoch 21/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8073\n","Epoch 22/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8307\n","Epoch 23/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7904\n","Epoch 24/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8203\n","Epoch 25/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8294\n","Epoch 26/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8490\n","Epoch 27/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8229\n","Epoch 28/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8203\n","Epoch 29/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8411\n","Epoch 30/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8581\n","Epoch 31/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8685\n","Epoch 32/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8516\n","Epoch 33/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8633\n","Epoch 34/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8125\n","Epoch 35/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8411\n","Epoch 36/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8555\n","Epoch 37/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8464\n","Epoch 38/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8620\n","Epoch 39/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8555\n","Epoch 40/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8424\n","Epoch 41/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8385\n","Epoch 42/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8594\n","Epoch 43/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8620\n","Epoch 44/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8451\n","Epoch 45/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8659\n","Epoch 46/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8607\n","Epoch 47/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8568\n","Epoch 48/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8294\n","Epoch 49/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8594\n","Epoch 50/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8424\n","Epoch 51/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8372\n","Epoch 52/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8333\n","Epoch 53/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8568\n","Epoch 54/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8815\n","Epoch 55/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8568\n","Epoch 56/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8633\n","Epoch 57/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8724\n","Epoch 58/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8685\n","Epoch 59/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8477\n","Epoch 60/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8776\n","Epoch 61/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8294\n","Epoch 62/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8568\n","Epoch 63/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8594\n","Epoch 64/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8737\n","Epoch 65/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8542\n","Epoch 66/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8737\n","Epoch 67/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8646\n","Epoch 68/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8659\n","Epoch 69/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.8802\n","Epoch 70/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8789\n","Epoch 71/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8724\n","Epoch 72/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8529\n","Epoch 73/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8568\n","Epoch 74/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8672\n","Epoch 75/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8672\n","Epoch 76/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8763\n","Epoch 77/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8789\n","Epoch 78/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8685\n","Epoch 79/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8581\n","Epoch 80/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8815\n","Epoch 81/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8724\n","Epoch 82/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8281\n","Epoch 83/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8581\n","Epoch 84/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8320\n","Epoch 85/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8294\n","Epoch 86/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8776\n","Epoch 87/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8685\n","Epoch 88/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8737\n","Epoch 89/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8672\n","Epoch 90/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8815\n","Epoch 91/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8490\n","Epoch 92/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8464\n","Epoch 93/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8685\n","Epoch 94/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8464\n","Epoch 95/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8516\n","Epoch 96/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.8802\n","Epoch 97/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8763\n","Epoch 98/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2791 - accuracy: 0.8867\n","Epoch 99/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8828\n","Epoch 100/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2716 - accuracy: 0.8854\n","Epoch 101/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8529\n","Epoch 102/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8451\n","Epoch 103/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.8672\n","Epoch 104/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8815\n","Epoch 105/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8802\n","Epoch 106/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.8737\n","Epoch 107/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2727 - accuracy: 0.8893\n","Epoch 108/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8776\n","Epoch 109/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2665 - accuracy: 0.8880\n","Epoch 110/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8503\n","Epoch 111/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8698\n","Epoch 112/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8125\n","Epoch 113/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3094 - accuracy: 0.8724\n","Epoch 114/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.8854\n","Epoch 115/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2681 - accuracy: 0.8893\n","Epoch 116/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8828\n","Epoch 117/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2790 - accuracy: 0.8880\n","Epoch 118/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8503\n","Epoch 119/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8594\n","Epoch 120/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2705 - accuracy: 0.8932\n","Epoch 121/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2575 - accuracy: 0.8971\n","Epoch 122/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2462 - accuracy: 0.8919\n","Epoch 123/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8594\n","Epoch 124/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3131 - accuracy: 0.8529\n","Epoch 125/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.2660 - accuracy: 0.8880\n","Epoch 126/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8802\n","Epoch 127/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8464\n","Epoch 128/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3038 - accuracy: 0.8646\n","Epoch 129/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.8867\n","Epoch 130/200\n","24/24 [==============================] - 0s 7ms/step - loss: 0.2566 - accuracy: 0.8880\n","Epoch 131/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8555\n","Epoch 132/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8594\n","Epoch 133/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8893\n","Epoch 134/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8646\n","Epoch 135/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8594\n","Epoch 136/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.8945\n","Epoch 137/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.8945\n","Epoch 138/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8828\n","Epoch 139/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9036\n","Epoch 140/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.8971\n","Epoch 141/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8646\n","Epoch 142/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.8893\n","Epoch 143/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.8997\n","Epoch 144/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.8997\n","Epoch 145/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8841\n","Epoch 146/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.8945\n","Epoch 147/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8867\n","Epoch 148/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8659\n","Epoch 149/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.8932\n","Epoch 150/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9010\n","Epoch 151/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8854\n","Epoch 152/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2286 - accuracy: 0.9049\n","Epoch 153/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9102\n","Epoch 154/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9049\n","Epoch 155/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9128\n","Epoch 156/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.8971\n","Epoch 157/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8932\n","Epoch 158/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.8932\n","Epoch 159/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.8880\n","Epoch 160/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9102\n","Epoch 161/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9102\n","Epoch 162/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.8932\n","Epoch 163/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8568\n","Epoch 164/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8971\n","Epoch 165/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8867\n","Epoch 166/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9036\n","Epoch 167/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9128\n","Epoch 168/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9115\n","Epoch 169/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9193\n","Epoch 170/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9284\n","Epoch 171/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9388\n","Epoch 172/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9323\n","Epoch 173/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9245\n","Epoch 174/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9115\n","Epoch 175/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2305 - accuracy: 0.8932\n","Epoch 176/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8672\n","Epoch 177/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9010\n","Epoch 178/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2264 - accuracy: 0.9102\n","Epoch 179/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9271\n","Epoch 180/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.8997\n","Epoch 181/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8945\n","Epoch 182/200\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2414 - accuracy: 0.8945\n","Epoch 183/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9219\n","Epoch 184/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9141\n","Epoch 185/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9154\n","Epoch 186/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9284\n","Epoch 187/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9453\n","Epoch 188/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9440\n","Epoch 189/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9531\n","Epoch 190/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9492\n","Epoch 191/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9284\n","Epoch 192/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9232\n","Epoch 193/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9531\n","Epoch 194/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9596\n","Epoch 195/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9479\n","Epoch 196/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9505\n","Epoch 197/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9466\n","Epoch 198/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9154\n","Epoch 199/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9323\n","Epoch 200/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9375\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9105\n","Accuracy: 0.9105058312416077\n"]}]}]}